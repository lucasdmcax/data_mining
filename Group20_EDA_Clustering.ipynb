{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "642b95d6",
   "metadata": {},
   "source": [
    "# Group 20 — Clustering\n",
    "\n",
    "This notebook performs exploratory data analysis on customer and flights databases, covering data inspection, quality assessment, and preprocessing.\n",
    "\n",
    "## Table of Contents\n",
    "- [Data Import](#data-import)\n",
    "- [Data Preprocessing](#preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34bb2db",
   "metadata": {},
   "source": [
    "# <a id=\"data-import\"></a> Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0215ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from collections import Counter\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Load the data\n",
    "\n",
    "customer_db = pd.read_csv(\"data/DM_AIAI_CustomerDB.csv\", index_col=0 )\n",
    "flights_db = pd.read_csv(\"data/DM_AIAI_FlightsDB.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdfe1cb",
   "metadata": {},
   "source": [
    "# <a id=\"preprocessing\"></a> Data Preprocessing\n",
    "\n",
    "In this section we apply the preprocessing and feature engineering steps\n",
    "described in the report:\n",
    "\n",
    "- Fix data types and logical inconsistencies in **FlightsDB**\n",
    "- Handle missing values and transform skewed variables in **CustomerDB**\n",
    "- Create new features: log-transformed variables, points utilisation,\n",
    "  cancellation flag, customer value score, flight activity score, and\n",
    "  average flight distance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d80a365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def preprocess_flights(flights_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply preprocessing steps to the FlightsDB:\n",
    "    - Convert YearMonthDate to datetime\n",
    "    - Round down NumFlights and NumFlightsWithCompanions\n",
    "    - Set DistanceKM = 0 where NumFlights == 0\n",
    "    - Drop DollarCostPointsRedeemed\n",
    "    - Add log-transformed versions of skewed variables\n",
    "    - Create PointsUtilizationRatio = PointsRedeemed / PointsAccumulated\n",
    "    \"\"\"\n",
    "    df = flights_df.copy()\n",
    "\n",
    "    # 1. YearMonthDate -> datetime\n",
    "    if 'YearMonthDate' in df.columns:\n",
    "        df['YearMonthDate'] = pd.to_datetime(df['YearMonthDate'])\n",
    "\n",
    "    # 2. Round down flight counts and cast to int\n",
    "    for col in ['NumFlights', 'NumFlightsWithCompanions']:\n",
    "        if col in df.columns:\n",
    "            df[col] = np.floor(df[col]).astype(int)\n",
    "\n",
    "    # 3. Fix logical inconsistency: DistanceKM must be 0 if NumFlights == 0\n",
    "    if {'NumFlights', 'DistanceKM'}.issubset(df.columns):\n",
    "        df.loc[df['NumFlights'] == 0, 'DistanceKM'] = 0\n",
    "\n",
    "    # 4. Drop perfectly correlated variable\n",
    "    if 'DollarCostPointsRedeemed' in df.columns:\n",
    "        df = df.drop(columns=['DollarCostPointsRedeemed'])\n",
    "\n",
    "    # 5. Log transforms for skewed numeric variables\n",
    "    log_cols = ['DistanceKM', 'PointsAccumulated', 'PointsRedeemed']\n",
    "    for col in log_cols:\n",
    "        if col in df.columns:\n",
    "            df[f'{col}_log'] = np.log1p(df[col])\n",
    "\n",
    "    # 6. Points utilisation ratio\n",
    "    if {'PointsRedeemed', 'PointsAccumulated'}.issubset(df.columns):\n",
    "        denom = df['PointsAccumulated'].replace({0: np.nan})\n",
    "        df['PointsUtilizationRatio'] = df['PointsRedeemed'] / denom\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_customers(customer_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply preprocessing steps to the CustomerDB:\n",
    "    - Create cancellation flag from CancellationDate\n",
    "    - Group-median imputation (by LoyaltyStatus) for Income and Customer Lifetime Value\n",
    "    - Log transform Customer Lifetime Value\n",
    "    - Create Location feature (region) from Province or State (placeholder mapping)\n",
    "    - Create CustomerValueScore composite feature\n",
    "    \"\"\"\n",
    "    df = customer_df.copy()\n",
    "\n",
    "    # 1. Cancellation flag\n",
    "    if 'CancellationDate' in df.columns:\n",
    "        df['CancelledFlag'] = df['CancellationDate'].notna().astype(int)\n",
    "\n",
    "    # 2. Group-median imputation by LoyaltyStatus\n",
    "    group_col = 'LoyaltyStatus'\n",
    "    cols_to_impute = ['Income', 'Customer Lifetime Value']\n",
    "    for col in cols_to_impute:\n",
    "        if col in df.columns and group_col in df.columns:\n",
    "            df[col] = df.groupby(group_col)[col].transform(\n",
    "                lambda x: x.fillna(x.median())\n",
    "            )\n",
    "\n",
    "    # 3. Log transform Customer Lifetime Value (for variance stabilisation)\n",
    "    if 'Customer Lifetime Value' in df.columns:\n",
    "        df['CustomerLifetimeValue_log'] = np.log1p(df['Customer Lifetime Value'])\n",
    "\n",
    "    # 4. Location feature (region mapping) – fill mapping as desired\n",
    "    if 'Province or State' in df.columns:\n",
    "        region_map = {\n",
    "            'Ontario': 'Central',\n",
    "            'Quebec': 'Quebec',\n",
    "            'British Columbia': 'West',\n",
    "            'Alberta': 'West',\n",
    "            'Saskatchewan': 'West',\n",
    "            'Manitoba': 'West',\n",
    "            'New Brunswick': 'Atlantic',\n",
    "            'Nova Scotia': 'Atlantic',\n",
    "            'Prince Edward Island': 'Atlantic',\n",
    "            'Newfoundland and Labrador': 'Atlantic',\n",
    "            'Yukon': 'North',\n",
    "            'Northwest Territories': 'North',\n",
    "            'Nunavut': 'North',\n",
    "        }\n",
    "\n",
    "        df['Location'] = df['Province or State'].map(region_map).fillna('Other')\n",
    "\n",
    "    # 5. Customer Value Score (simple composite of CLV and Income)\n",
    "    clv_col = 'CustomerLifetimeValue_log'\n",
    "    if clv_col in df.columns:\n",
    "        clv_scaled = (df[clv_col] - df[clv_col].mean()) / df[clv_col].std(ddof=0)\n",
    "\n",
    "        if 'Income' in df.columns:\n",
    "            income_log = np.log1p(df['Income'].clip(lower=0))\n",
    "            income_scaled = (income_log - income_log.mean()) / income_log.std(ddof=0)\n",
    "            # Heavier weight on CLV, lighter on Income\n",
    "            df['CustomerValueScore'] = 0.7 * clv_scaled + 0.3 * income_scaled\n",
    "        else:\n",
    "            df['CustomerValueScore'] = clv_scaled\n",
    "\n",
    "    return df\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be98085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_customer_flight_features(flights_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregate monthly flight records into customer-level features:\n",
    "    - TotalFlights, TotalDistanceKM, TotalPointsAccumulated, TotalPointsRedeemed\n",
    "    - MeanPointsUtilization\n",
    "    - AverageFlightDistance\n",
    "    - FlightActivityScore (based on z-scores of flights and distance)\n",
    "    \"\"\"\n",
    "    id_col = 'Loyalty#'\n",
    "    df = flights_df.copy()\n",
    "\n",
    "    agg = (\n",
    "        df\n",
    "        .groupby(id_col)\n",
    "        .agg(\n",
    "            TotalFlights=('NumFlights', 'sum'),\n",
    "            TotalDistanceKM=('DistanceKM', 'sum'),\n",
    "            TotalPointsAccumulated=('PointsAccumulated', 'sum'),\n",
    "            TotalPointsRedeemed=('PointsRedeemed', 'sum'),\n",
    "            MeanPointsUtilization=('PointsUtilizationRatio', 'mean')\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Average flight distance = total distance / total flights\n",
    "    agg['AverageFlightDistance'] = agg['TotalDistanceKM'] / agg['TotalFlights'].replace({0: np.nan})\n",
    "\n",
    "    # FlightActivityScore: combines total flights and distance (z-scores)\n",
    "    for col in ['TotalFlights', 'TotalDistanceKM']:\n",
    "        mean = agg[col].mean()\n",
    "        std = agg[col].std(ddof=0)\n",
    "        if std == 0:\n",
    "            agg[f'{col}_z'] = 0\n",
    "        else:\n",
    "            agg[f'{col}_z'] = (agg[col] - mean) / std\n",
    "\n",
    "    agg['FlightActivityScore'] = agg['TotalFlights_z'] + agg['TotalDistanceKM_z']\n",
    "\n",
    "    return agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b70b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run preprocessing for each table\n",
    "customer_preprocessed = preprocess_customers(customer_db)\n",
    "flights_preprocessed = preprocess_flights(flights_db)\n",
    "\n",
    "# Build customer-level flight features\n",
    "customer_flight_features = build_customer_flight_features(flights_preprocessed)\n",
    "\n",
    "# Merge into a single modelling dataset (one row per customer)\n",
    "id_col = 'Loyalty#'\n",
    "model_df = (\n",
    "    customer_preprocessed\n",
    "    .merge(customer_flight_features, on=id_col, how='left')\n",
    ")\n",
    "\n",
    "print(\"Customer-preprocessed shape:\", customer_preprocessed.shape)\n",
    "print(\"Flights-preprocessed shape:\", flights_preprocessed.shape)\n",
    "print(\"Model dataset shape:\", model_df.shape)\n",
    "\n",
    "model_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9406aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def winsorize_dataframe(df, columns, limits=(0.01, 0.01)):\n",
    "    \"\"\"\n",
    "    Apply winsorization to each column in `columns`.\n",
    "    limits=(lower_pct, upper_pct) means: cap values at the 1st and 99th percentile.\n",
    "\n",
    "    Returns the winsorized copy of df.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            # winsorize returns masked arrays -> convert to normal array\n",
    "            df[col] = winsorize(df[col], limits=limits).data\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec94257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_outlier_cols = [\n",
    "    'TotalFlights',\n",
    "    'TotalDistanceKM',\n",
    "    'TotalPointsAccumulated',\n",
    "    'TotalPointsRedeemed',\n",
    "    'AverageFlightDistance'\n",
    "]\n",
    "\n",
    "customer_flight_features_wins = winsorize_dataframe(\n",
    "    customer_flight_features,\n",
    "    columns=flight_outlier_cols,\n",
    "    limits=(0.01, 0.01)    # winsorize at 1% and 99%\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c1957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_outlier_cols = [\n",
    "    'Income',\n",
    "    'Customer Lifetime Value',\n",
    "    'CustomerLifetimeValue_log'\n",
    "]\n",
    "\n",
    "customer_preprocessed_wins = winsorize_dataframe(\n",
    "    customer_preprocessed,\n",
    "    columns=customer_outlier_cols,\n",
    "    limits=(0.01, 0.01)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c5f2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = 'Loyalty#'\n",
    "\n",
    "model_df = (\n",
    "    customer_preprocessed_wins\n",
    "    .merge(customer_flight_features_wins, on=id_col, how='left')\n",
    ")\n",
    "\n",
    "print(\"Final model_df shape:\", model_df.shape)\n",
    "model_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe01dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for remaining missing values\n",
    "model_df.isna().sum().sort_values(ascending=False).head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f0cd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop CancellationDate (flag already exists)\n",
    "model_df = model_df.drop(columns=['CancellationDate'], errors='ignore')\n",
    "\n",
    "# Fill average distance for zero-flight customers\n",
    "model_df['AverageFlightDistance'] = model_df['AverageFlightDistance'].fillna(0)\n",
    "\n",
    "# Fill points utilization for customers with no point activity\n",
    "model_df['MeanPointsUtilization'] = model_df['MeanPointsUtilization'].fillna(0)\n",
    "\n",
    "# Fill ALL flight-related NaNs with 0\n",
    "flight_cols = [\n",
    "    'TotalFlights', 'TotalDistanceKM', 'TotalPointsAccumulated',\n",
    "    'TotalPointsRedeemed', 'MeanPointsUtilization', 'AverageFlightDistance',\n",
    "    'TotalFlights_z', 'TotalDistanceKM_z', 'FlightActivityScore'\n",
    "]\n",
    "\n",
    "for col in flight_cols:\n",
    "    model_df[col] = model_df[col].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6927b2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features for clustering\n",
    "numeric_features = [\n",
    "    'Income',\n",
    "    'CustomerLifetimeValue_log',\n",
    "    'CustomerValueScore',\n",
    "    \n",
    "    'TotalFlights',\n",
    "    'TotalDistanceKM',\n",
    "    'AverageFlightDistance',\n",
    "    'TotalPointsAccumulated',\n",
    "    'TotalPointsRedeemed',\n",
    "    'MeanPointsUtilization',\n",
    "    'FlightActivityScore',\n",
    "\n",
    "    'CancelledFlag'\n",
    "]\n",
    "\n",
    "# Categorical features to encode\n",
    "categorical_features = [\n",
    "    'EnrollmentType',  # Bronze, Silver, Gold ...\n",
    "    'Location'         # Region/Province after mapping\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed99397",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected = model_df[numeric_features + categorical_features].copy()\n",
    "df_selected.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e15d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df_selected, columns=categorical_features, drop_first=True)\n",
    "df_encoded.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6296ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_encoded)\n",
    "\n",
    "X_scaled[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca7e97d",
   "metadata": {},
   "source": [
    "# DBSCAN \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4061e8",
   "metadata": {},
   "source": [
    "To identify anomalous customer behavior, the DBSCAN algorithm was applied to the scaled feature space. In this project, DBSCAN is used exclusively for outlier detection, not for final customer segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3419c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=1.9, min_samples=20, n_jobs=1)\n",
    "dbscan_labels = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "outlier_count = Counter(dbscan_labels)\n",
    "print(f\"DBSCAN results: {outlier_count}\")\n",
    "print(f\"Outliers detected: {outlier_count.get(-1, 0)}\")\n",
    "print(f\"Core customers: {outlier_count.get(0, 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079bff82",
   "metadata": {},
   "source": [
    "The algorithm identified multiple dense regions in the data, reflecting local behavioral patterns across customers. A small fraction of observations was classified as noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22761fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_mask = (dbscan_labels != -1)\n",
    "\n",
    "X_scaled_core = X_scaled[core_mask]\n",
    "\n",
    "print(f\"Core customers kept: {len(X_scaled_core):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bdc07e",
   "metadata": {},
   "source": [
    "DBSCAN successfully identified a small proportion of anomalous customers (~5%), while preserving the vast majority of the dataset for subsequent analysis. This confirms that most customers exhibit consistent behavior, and that outliers can be safely removed to improve the robustness of downstream clustering and modeling tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293b6a4a",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0029d498",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m labels \u001b[38;5;241m=\u001b[39m kmeans\u001b[38;5;241m.\u001b[39mfit_predict(X_scaled_core)\n\u001b[0;32m     14\u001b[0m inertias\u001b[38;5;241m.\u001b[39mappend(kmeans\u001b[38;5;241m.\u001b[39minertia_)\n\u001b[1;32m---> 15\u001b[0m silhouettes\u001b[38;5;241m.\u001b[39mappend(\u001b[43msilhouette_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_scaled_core\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\joaop\\OneDrive\\anaconda\\envs\\Fall2526\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    214\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    215\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    216\u001b[0m         )\n\u001b[0;32m    217\u001b[0m     ):\n\u001b[1;32m--> 218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    228\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\joaop\\OneDrive\\anaconda\\envs\\Fall2526\\Lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:146\u001b[0m, in \u001b[0;36msilhouette_score\u001b[1;34m(X, labels, metric, sample_size, random_state, **kwds)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m         X, labels \u001b[38;5;241m=\u001b[39m X[indices], labels[indices]\n\u001b[1;32m--> 146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(\u001b[43msilhouette_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[1;32mc:\\Users\\joaop\\OneDrive\\anaconda\\envs\\Fall2526\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:191\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\joaop\\OneDrive\\anaconda\\envs\\Fall2526\\Lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:310\u001b[0m, in \u001b[0;36msilhouette_samples\u001b[1;34m(X, labels, metric, **kwds)\u001b[0m\n\u001b[0;32m    306\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metric\n\u001b[0;32m    307\u001b[0m reduce_func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[0;32m    308\u001b[0m     _silhouette_reduce, labels\u001b[38;5;241m=\u001b[39mlabels, label_freqs\u001b[38;5;241m=\u001b[39mlabel_freqs\n\u001b[0;32m    309\u001b[0m )\n\u001b[1;32m--> 310\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpairwise_distances_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    311\u001b[0m intra_clust_dists, inter_clust_dists \u001b[38;5;241m=\u001b[39m results\n\u001b[0;32m    312\u001b[0m intra_clust_dists \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(intra_clust_dists)\n",
      "File \u001b[1;32mc:\\Users\\joaop\\OneDrive\\anaconda\\envs\\Fall2526\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2264\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   2262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2263\u001b[0m     X_chunk \u001b[38;5;241m=\u001b[39m X[sl]\n\u001b[1;32m-> 2264\u001b[0m D_chunk \u001b[38;5;241m=\u001b[39m \u001b[43mpairwise_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   2266\u001b[0m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2267\u001b[0m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   2268\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[0;32m   2269\u001b[0m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[0;32m   2270\u001b[0m     D_chunk\u001b[38;5;241m.\u001b[39mflat[sl\u001b[38;5;241m.\u001b[39mstart :: _num_samples(X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\joaop\\OneDrive\\anaconda\\envs\\Fall2526\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:191\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\joaop\\OneDrive\\anaconda\\envs\\Fall2526\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2473\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, ensure_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2470\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m   2471\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m-> 2473\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parallel_pairwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joaop\\OneDrive\\anaconda\\envs\\Fall2526\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1969\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1966\u001b[0m     Y \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m   1968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1969\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1971\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1972\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_transposed_dist_wrapper)\n",
      "File \u001b[1;32mc:\\Users\\joaop\\OneDrive\\anaconda\\envs\\Fall2526\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:191\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\joaop\\OneDrive\\anaconda\\envs\\Fall2526\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:371\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Y_norm_squared\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m1\u001b[39m, Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m    366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    367\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible dimensions for Y of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    368\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY_norm_squared of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    369\u001b[0m         )\n\u001b[1;32m--> 371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_euclidean_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joaop\\OneDrive\\anaconda\\envs\\Fall2526\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:407\u001b[0m, in \u001b[0;36m_euclidean_distances\u001b[1;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[0;32m    404\u001b[0m     distances \u001b[38;5;241m=\u001b[39m _euclidean_distances_upcast(X, XX, Y, YY)\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;66;03m# if dtype is already float64, no need to chunk and upcast\u001b[39;00m\n\u001b[1;32m--> 407\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m XX\n\u001b[0;32m    409\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m YY\n",
      "File \u001b[1;32mc:\\Users\\joaop\\OneDrive\\anaconda\\envs\\Fall2526\\Lib\\site-packages\\sklearn\\utils\\extmath.py:230\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    227\u001b[0m     ret \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m@\u001b[39m b\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m--> 230\u001b[0m     \u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    234\u001b[0m ):\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\joaop\\OneDrive\\anaconda\\envs\\Fall2526\\Lib\\site-packages\\scipy\\sparse\\_base.py:1513\u001b[0m, in \u001b[0;36missparse\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1508\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m sparray\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m _spbase\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\n\u001b[1;32m-> 1513\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21missparse\u001b[39m(x):\n\u001b[0;32m   1514\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Is `x` of a sparse array or sparse matrix type?\u001b[39;00m\n\u001b[0;32m   1515\u001b[0m \n\u001b[0;32m   1516\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, _spbase)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inertias = []\n",
    "silhouettes = []\n",
    "K = range(2, 11)\n",
    "\n",
    "for k in K:\n",
    "    kmeans = KMeans(\n",
    "        n_clusters=k,\n",
    "        init='k-means++',\n",
    "        random_state=42,\n",
    "        n_init=20\n",
    "    )\n",
    "    labels = kmeans.fit_predict(X_scaled_core)\n",
    "    \n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouettes.append(silhouette_score(X_scaled_core, labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fall2526",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
