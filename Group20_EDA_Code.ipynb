{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "642b95d6",
   "metadata": {},
   "source": [
    "# Group 20 — Exploratory Data Analysis\n",
    "\n",
    "This notebook performs exploratory data analysis on customer and flights databases, covering data inspection, quality assessment, and preprocessing.\n",
    "\n",
    "## Table of Contents\n",
    "- [Data Import](#data-import)\n",
    "- [Data Inspection](#data-inspection)\n",
    "  - [Customer DB](#customer-db)\n",
    "  - [Flights DB](#flights-db)\n",
    "- [Missing Values](#missing-values)\n",
    "- [Outliers](#outliers)\n",
    "  - [Customer DB Outliers](#customer-outliers)\n",
    "  - [Flights DB Outliers](#flights-outliers)\n",
    "- [Correlations](#correlations)\n",
    "- [Miscellaneous Analyses](#miscellaneous)\n",
    "  - [Categorical Distributions](#categorical-distributions)\n",
    "  - [Relationship Analysis](#relationship-analysis)\n",
    "  - [Points Redemption Analysis](#points-redemption)\n",
    "  - [Geospatial Analysis](#geospatial-analysis)\n",
    "- [Data Preprocessing](#preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34bb2db",
   "metadata": {},
   "source": [
    "# <a id=\"data-import\"></a> Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0215ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Load the data\n",
    "\n",
    "customer_db = pd.read_csv(\"data/DM_AIAI_CustomerDB.csv\", index_col=0 )\n",
    "flights_db = pd.read_csv(\"data/DM_AIAI_FlightsDB.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3073ffd5",
   "metadata": {},
   "source": [
    "# <a id=\"data-inspection\"></a> Data Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4388d9cb",
   "metadata": {},
   "source": [
    "### <a id=\"customer-db\"></a> Customer DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f289a5ee",
   "metadata": {},
   "source": [
    "## Basic Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9216492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f61b25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_db.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82431c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate loyalty IDs\n",
    "duplicated_loyalty_ids = customer_db[customer_db['Loyalty#'].duplicated()]['Loyalty#'].unique()\n",
    "print(f\"Number of unique Duplicated Loyalty IDs: {len(duplicated_loyalty_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee4a6d0",
   "metadata": {},
   "source": [
    "## <a id=\"flights-db\"></a> Flights DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1243ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9cd868-32dd-4fb0-8860-36f8dbbd798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_db.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fac10bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for fractional flight counts\n",
    "invalid_fractional_flights = flights_db[\n",
    "    (flights_db['NumFlights'] % 1 != 0) |\n",
    "    (flights_db['NumFlightsWithCompanions'] % 1 != 0)\n",
    "]\n",
    "\n",
    "print(f\"Number of rows with fractional flight counts: {len(invalid_fractional_flights)}\")\n",
    "if not invalid_fractional_flights.empty:\n",
    "    display(invalid_fractional_flights[['Year', 'Month', 'NumFlights', 'NumFlightsWithCompanions']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d04fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for inconsistent flight records (NumFlights=0 but DistanceKM>0)\n",
    "invalid_flights = flights_db[(flights_db['NumFlights'] == 0) & (flights_db['DistanceKM'] > 0)]\n",
    "\n",
    "print(f\"Number of inconsistent rows (NumFlights=0 & DistanceKM>0): {len(invalid_flights)}\")\n",
    "if not invalid_flights.empty:\n",
    "    display(invalid_flights.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216fa7a8",
   "metadata": {},
   "source": [
    "# <a id=\"missing-values\"></a> Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab33c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_report(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.isna().agg(['sum', 'mean']).T\n",
    "    out.columns = ['Total', 'Percentage']\n",
    "    out['Percentage'] = (out['Percentage'] * 100).round(2)\n",
    "    return out.sort_values(['Total', 'Percentage'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509e1f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Customer DB Missing Values:\")\n",
    "customer_missing = missing_report(customer_db)\n",
    "customer_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bfa04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Flights DB Missing Values:\")\n",
    "flights_missing = missing_report(flights_db)\n",
    "flights_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff4a99f",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "**Customer DB:** CancellationDate has 86% missing values (expected for active customers). Income and Customer Lifetime Value have minimal missing data (0.12%). All other columns are complete.\n",
    "\n",
    "**Flights DB:** No missing values detected. Dataset has excellent completeness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37de14d",
   "metadata": {},
   "source": [
    "# <a id=\"outliers\"></a> Outliers Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4257b0e9",
   "metadata": {},
   "source": [
    "## <a id=\"customer-outliers\"></a> Customer DB Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fe023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"Income\", \"Customer Lifetime Value\"]\n",
    "\n",
    "# Histograms\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "for ax, feat in zip(axes.flatten(), numeric_features):\n",
    "    ax.hist(customer_db[feat].dropna(), bins=30)\n",
    "    ax.set_title(feat)\n",
    "plt.suptitle(\"Customer DB - Histograms\")\n",
    "plt.show()\n",
    "\n",
    "# Boxplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "for ax, feat in zip(axes.flatten(), numeric_features):\n",
    "    sns.boxplot(data=customer_db, y=feat, ax=ax)\n",
    "    ax.set_title(feat)\n",
    "plt.suptitle(\"Customer DB - Boxplots\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece0cc0b",
   "metadata": {},
   "source": [
    "## <a id=\"flights-outliers\"></a> Flights DB Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fca67f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"NumFlights\", \"NumFlightsWithCompanions\", \"DistanceKM\", \n",
    "                    \"PointsAccumulated\", \"PointsRedeemed\", \"DollarCostPointsRedeemed\"]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "for ax, feat in zip(axes.flatten(), numeric_features):\n",
    "    sns.boxplot(data=flights_db, y=feat, ax=ax)\n",
    "    ax.set_title(feat)\n",
    "plt.suptitle(\"Flights DB - Boxplots\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158945b9",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "**Customer DB:** Both Income and Customer Lifetime Value show right-skewed distributions with numerous outliers. Many customers have zero or near-zero income (likely students), while a small segment has very high income.\n",
    "\n",
    "**Flights DB:** All flight-related metrics exhibit right skewness with outliers representing highly active frequent flyers. These outliers are legitimate and represent valuable customers rather than data errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48809650",
   "metadata": {},
   "source": [
    "# <a id=\"correlations\"></a> Correlations Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7881d5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"NumFlights\", \"NumFlightsWithCompanions\", \"DistanceKM\", \n",
    "                    \"PointsAccumulated\", \"PointsRedeemed\", \"DollarCostPointsRedeemed\"]\n",
    "\n",
    "corr = flights_db[numeric_features].corr(method=\"pearson\")\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data=corr, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title(\"Flights DB - Correlation Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9de53bc",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "| Pair | Correlation | Interpretation |\n",
    "|------|--------------|----------------|\n",
    "| NumFlights and DistanceKM | 0.62 | Strong positive — more flights generally means more total distance flown. |\n",
    "| NumFlights and PointsAccumulated | 0.62 | Strong positive — more flights results in more points earned. |\n",
    "| NumFlights and NumFlightsWithCompanions | 0.51 | Moderate positive — people who fly often also tend to fly with companions more. |\n",
    "| NumFlightsWithCompanions and DistanceKM | 0.39 | Moderate — more companion flights slightly increase total distance. |\n",
    "| PointsRedeemed and DollarCostPointsRedeemed | 1.00 | Perfect correlation — these two represent the same underlying concept (points redeemed vs. their dollar cost).\n",
    "| PointsRedeemed and NumFlights / DistanceKM / PointsAccumulated | 0.19–0.34 | Weak relationships — redeeming points doesn’t strongly depend on flying behavior in this dataset. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52f88f0",
   "metadata": {},
   "source": [
    "# <a id=\"miscellaneous\"></a> Miscellaneous Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851958f7",
   "metadata": {},
   "source": [
    "## <a id=\"categorical-distributions\"></a> Categorical Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2978acd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['Province or State', 'City', 'Gender', 'Education',\n",
    "                    'Location Code', 'Marital Status', 'LoyaltyStatus', 'EnrollmentType']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=math.ceil(len(categorical_cols) / 3), ncols=3, figsize=(15, 15))\n",
    "\n",
    "for ax, col in zip(axes.flatten(), categorical_cols):\n",
    "    customer_db[col].value_counts().plot(kind='barh', ax=ax, title=f'Distribution of {col}')\n",
    "    ax.set_xlabel(\"Count\")\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1504a108",
   "metadata": {},
   "source": [
    "## <a id=\"relationship-analysis\"></a> Relationship Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0902ae2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer DB: Income vs Customer Lifetime Value\n",
    "sns.scatterplot(data=customer_db, x='Income', y='Customer Lifetime Value', alpha=0.6)\n",
    "plt.title('Income vs Customer Lifetime Value')\n",
    "plt.show()\n",
    "\n",
    "# Income by Loyalty Status\n",
    "sns.boxplot(x='LoyaltyStatus', y='Income', data=customer_db.dropna(subset=['Income']))\n",
    "plt.title('Income by Loyalty Tier')\n",
    "plt.xlabel('Loyalty Tier')\n",
    "plt.ylabel('Income')\n",
    "plt.show()\n",
    "\n",
    "# Income statistics by Loyalty Status\n",
    "customer_db.groupby('LoyaltyStatus')['Income'].agg(['count', 'mean', 'median'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6200701",
   "metadata": {},
   "source": [
    "**Income vs CLV:** Weak relationship indicates that customer value is driven by factors beyond income, such as travel frequency and engagement with loyalty programs.\n",
    "\n",
    "**Income by Loyalty Status:** Income distribution appears similar across loyalty tiers, suggesting the program is accessible to all income levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cf2e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA test: Income vs Education\n",
    "groups = [group[\"Income\"].dropna() for _, group in customer_db.groupby(\"Education\")]\n",
    "f_stat, p_val = stats.f_oneway(*groups)\n",
    "print(f\"ANOVA F-statistic: {f_stat:.3f}, p-value: {p_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9845584",
   "metadata": {},
   "source": [
    "**ANOVA Result:** Tests whether income differs significantly across education levels (Bachelor, College, etc.). A low p-value (<0.05) would indicate significant differences in income by education level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3657858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flights DB: Pairplot of key features\n",
    "numeric_features = [\"NumFlights\", \"NumFlightsWithCompanions\", \"DistanceKM\", \n",
    "                    \"PointsAccumulated\", \"PointsRedeemed\", \"DollarCostPointsRedeemed\"]\n",
    "\n",
    "g = sns.pairplot(data=flights_db[numeric_features].sample(5000, random_state=42),\n",
    "                 diag_kind='scatter', plot_kws={'alpha': 0.5}, height=2)\n",
    "plt.suptitle('Flights DB - Feature Relationships', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a2b397",
   "metadata": {},
   "source": [
    "**Pairplot Analysis:** Visualizes relationships between all flight-related features. Strong diagonal patterns indicate perfect correlations (e.g., DistanceKM vs PointsAccumulated), while scattered plots show weak or no relationships (e.g., redemption vs flight activity)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecf5fb2",
   "metadata": {},
   "source": [
    "**Key Insights:**\n",
    "- No clear linear relationship between Income and CLV\n",
    "- High variance in CLV across all income levels suggests other factors drive customer value\n",
    "- Strong positive relationships between flight frequency, distance, and points accumulated\n",
    "- Redemption behavior appears independent of flight activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc973e1",
   "metadata": {},
   "source": [
    "## <a id=\"points-redemption\"></a> Points Redemption Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7f25e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_accumulated = flights_db['PointsAccumulated'].sum()\n",
    "points_redeemed = flights_db['PointsRedeemed'].sum()\n",
    "points_non_redeemed = points_accumulated - points_redeemed\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sizes = [points_non_redeemed, points_redeemed]\n",
    "labels = ['Points Non-Redeemed', 'Points Redeemed']\n",
    "colors = ['#66b3ff', '#ff9999']\n",
    "\n",
    "ax.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "       wedgeprops={\"linewidth\": 1, \"edgecolor\": \"white\"})\n",
    "plt.title('Points Redemption Distribution')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d63321",
   "metadata": {},
   "source": [
    "**Points Redemption Overview:** Shows the proportion of loyalty points that have been redeemed vs those still available. High unredeemed percentage suggests opportunity for campaigns to increase engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1480d7a0",
   "metadata": {},
   "source": [
    "## <a id=\"geospatial-analysis\"></a> Geospatial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bee472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographic distribution of customers\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Scatter plot of customer locations with Canada boundaries\n",
    "axes[0].scatter(customer_db['Longitude'], customer_db['Latitude'], alpha=0.6, s=15, c='red', edgecolor='darkred')\n",
    "axes[0].set_xlabel('Longitude')\n",
    "axes[0].set_ylabel('Latitude')\n",
    "axes[0].set_title('Customer Geographic Distribution Across Canada')\n",
    "axes[0].set_xlim(-141, -52)  # Canada longitude range\n",
    "axes[0].set_ylim(41, 70)      # Canada latitude range\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Province distribution\n",
    "province_counts = customer_db['Province or State'].value_counts()\n",
    "axes[1].barh(province_counts.index, province_counts.values, color='steelblue')\n",
    "axes[1].set_xlabel('Number of Customers')\n",
    "axes[1].set_title('Customers by Province/State')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total unique locations: {customer_db[['Latitude', 'Longitude']].drop_duplicates().shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd293b9",
   "metadata": {},
   "source": [
    "**Geographic Distribution:** Map shows customer locations concentrated in southern Canada's major urban areas. Eastern provinces (Ontario, Quebec) and western coast (British Columbia) have highest customer density, reflecting population distribution patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdfe1cb",
   "metadata": {},
   "source": [
    "# <a id=\"preprocessing\"></a> Data Preprocessing\n",
    "\n",
    "In this section we apply the preprocessing and feature engineering steps\n",
    "described in the report:\n",
    "\n",
    "- Fix data types and logical inconsistencies in **FlightsDB**\n",
    "- Handle missing values and transform skewed variables in **CustomerDB**\n",
    "- Create new features: log-transformed variables, points utilisation,\n",
    "  cancellation flag, customer value score, flight activity score, and\n",
    "  average flight distance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d80a365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def preprocess_flights(flights_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply preprocessing steps to the FlightsDB:\n",
    "    - Convert YearMonthDate to datetime\n",
    "    - Round down NumFlights and NumFlightsWithCompanions\n",
    "    - Set DistanceKM = 0 where NumFlights == 0\n",
    "    - Drop DollarCostPointsRedeemed\n",
    "    - Add log-transformed versions of skewed variables\n",
    "    - Create PointsUtilizationRatio = PointsRedeemed / PointsAccumulated\n",
    "    \"\"\"\n",
    "    df = flights_df.copy()\n",
    "\n",
    "    # 1. YearMonthDate -> datetime\n",
    "    if 'YearMonthDate' in df.columns:\n",
    "        df['YearMonthDate'] = pd.to_datetime(df['YearMonthDate'])\n",
    "\n",
    "    # 2. Round down flight counts and cast to int\n",
    "    for col in ['NumFlights', 'NumFlightsWithCompanions']:\n",
    "        if col in df.columns:\n",
    "            df[col] = np.floor(df[col]).astype(int)\n",
    "\n",
    "    # 3. Fix logical inconsistency: DistanceKM must be 0 if NumFlights == 0\n",
    "    if {'NumFlights', 'DistanceKM'}.issubset(df.columns):\n",
    "        df.loc[df['NumFlights'] == 0, 'DistanceKM'] = 0\n",
    "\n",
    "    # 4. Drop perfectly correlated variable\n",
    "    if 'DollarCostPointsRedeemed' in df.columns:\n",
    "        df = df.drop(columns=['DollarCostPointsRedeemed'])\n",
    "\n",
    "    # 5. Log transforms for skewed numeric variables\n",
    "    log_cols = ['DistanceKM', 'PointsAccumulated', 'PointsRedeemed']\n",
    "    for col in log_cols:\n",
    "        if col in df.columns:\n",
    "            df[f'{col}_log'] = np.log1p(df[col])\n",
    "\n",
    "    # 6. Points utilisation ratio\n",
    "    if {'PointsRedeemed', 'PointsAccumulated'}.issubset(df.columns):\n",
    "        denom = df['PointsAccumulated'].replace({0: np.nan})\n",
    "        df['PointsUtilizationRatio'] = df['PointsRedeemed'] / denom\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_customers(customer_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply preprocessing steps to the CustomerDB:\n",
    "    - Create cancellation flag from CancellationDate\n",
    "    - Group-median imputation (by LoyaltyStatus) for Income and Customer Lifetime Value\n",
    "    - Log transform Customer Lifetime Value\n",
    "    - Create Location feature (region) from Province or State (placeholder mapping)\n",
    "    - Create CustomerValueScore composite feature\n",
    "    \"\"\"\n",
    "    df = customer_df.copy()\n",
    "\n",
    "    # 1. Cancellation flag\n",
    "    if 'CancellationDate' in df.columns:\n",
    "        df['CancelledFlag'] = df['CancellationDate'].notna().astype(int)\n",
    "\n",
    "    # 2. Group-median imputation by LoyaltyStatus\n",
    "    group_col = 'LoyaltyStatus'\n",
    "    cols_to_impute = ['Income', 'Customer Lifetime Value']\n",
    "    for col in cols_to_impute:\n",
    "        if col in df.columns and group_col in df.columns:\n",
    "            df[col] = df.groupby(group_col)[col].transform(\n",
    "                lambda x: x.fillna(x.median())\n",
    "            )\n",
    "\n",
    "    # 3. Log transform Customer Lifetime Value (for variance stabilisation)\n",
    "    if 'Customer Lifetime Value' in df.columns:\n",
    "        df['CustomerLifetimeValue_log'] = np.log1p(df['Customer Lifetime Value'])\n",
    "\n",
    "    # 4. Location feature (region mapping) – fill mapping as desired\n",
    "    if 'Province or State' in df.columns:\n",
    "        region_map = {\n",
    "            # Example mapping – adjust to your data\n",
    "            # 'Ontario': 'Central',\n",
    "            # 'Quebec': 'Central',\n",
    "            # 'British Columbia': 'West',\n",
    "            # 'Alberta': 'West',\n",
    "            # 'Nova Scotia': 'East',\n",
    "            # ...\n",
    "        }\n",
    "        df['Location'] = df['Province or State'].map(region_map).fillna(df['Province or State'])\n",
    "\n",
    "    # 5. Customer Value Score (simple composite of CLV and Income)\n",
    "    clv_col = 'CustomerLifetimeValue_log'\n",
    "    if clv_col in df.columns:\n",
    "        clv_scaled = (df[clv_col] - df[clv_col].mean()) / df[clv_col].std(ddof=0)\n",
    "\n",
    "        if 'Income' in df.columns:\n",
    "            income_log = np.log1p(df['Income'].clip(lower=0))\n",
    "            income_scaled = (income_log - income_log.mean()) / income_log.std(ddof=0)\n",
    "            # Heavier weight on CLV, lighter on Income\n",
    "            df['CustomerValueScore'] = 0.7 * clv_scaled + 0.3 * income_scaled\n",
    "        else:\n",
    "            df['CustomerValueScore'] = clv_scaled\n",
    "\n",
    "    return df\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be98085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_customer_flight_features(flights_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregate monthly flight records into customer-level features:\n",
    "    - TotalFlights, TotalDistanceKM, TotalPointsAccumulated, TotalPointsRedeemed\n",
    "    - MeanPointsUtilization\n",
    "    - AverageFlightDistance\n",
    "    - FlightActivityScore (based on z-scores of flights and distance)\n",
    "    \"\"\"\n",
    "    id_col = 'Loyalty#'\n",
    "    df = flights_df.copy()\n",
    "\n",
    "    agg = (\n",
    "        df\n",
    "        .groupby(id_col)\n",
    "        .agg(\n",
    "            TotalFlights=('NumFlights', 'sum'),\n",
    "            TotalDistanceKM=('DistanceKM', 'sum'),\n",
    "            TotalPointsAccumulated=('PointsAccumulated', 'sum'),\n",
    "            TotalPointsRedeemed=('PointsRedeemed', 'sum'),\n",
    "            MeanPointsUtilization=('PointsUtilizationRatio', 'mean')\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Average flight distance = total distance / total flights\n",
    "    agg['AverageFlightDistance'] = agg['TotalDistanceKM'] / agg['TotalFlights'].replace({0: np.nan})\n",
    "\n",
    "    # FlightActivityScore: combines total flights and distance (z-scores)\n",
    "    for col in ['TotalFlights', 'TotalDistanceKM']:\n",
    "        mean = agg[col].mean()\n",
    "        std = agg[col].std(ddof=0)\n",
    "        if std == 0:\n",
    "            agg[f'{col}_z'] = 0\n",
    "        else:\n",
    "            agg[f'{col}_z'] = (agg[col] - mean) / std\n",
    "\n",
    "    agg['FlightActivityScore'] = agg['TotalFlights_z'] + agg['TotalDistanceKM_z']\n",
    "\n",
    "    return agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b70b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run preprocessing for each table\n",
    "customer_preprocessed = preprocess_customers(customer_db)\n",
    "flights_preprocessed = preprocess_flights(flights_db)\n",
    "\n",
    "# Build customer-level flight features\n",
    "customer_flight_features = build_customer_flight_features(flights_preprocessed)\n",
    "\n",
    "# Merge into a single modelling dataset (one row per customer)\n",
    "id_col = 'Loyalty#'\n",
    "model_df = (\n",
    "    customer_preprocessed\n",
    "    .merge(customer_flight_features, on=id_col, how='left')\n",
    ")\n",
    "\n",
    "print(\"Customer-preprocessed shape:\", customer_preprocessed.shape)\n",
    "print(\"Flights-preprocessed shape:\", flights_preprocessed.shape)\n",
    "print(\"Model dataset shape:\", model_df.shape)\n",
    "\n",
    "model_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9406aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def winsorize_dataframe(df, columns, limits=(0.01, 0.01)):\n",
    "    \"\"\"\n",
    "    Apply winsorization to each column in `columns`.\n",
    "    limits=(lower_pct, upper_pct) means: cap values at the 1st and 99th percentile.\n",
    "\n",
    "    Returns the winsorized copy of df.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            # winsorize returns masked arrays -> convert to normal array\n",
    "            df[col] = winsorize(df[col], limits=limits).data\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec94257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_outlier_cols = [\n",
    "    'TotalFlights',\n",
    "    'TotalDistanceKM',\n",
    "    'TotalPointsAccumulated',\n",
    "    'TotalPointsRedeemed',\n",
    "    'AverageFlightDistance'\n",
    "]\n",
    "\n",
    "customer_flight_features_wins = winsorize_dataframe(\n",
    "    customer_flight_features,\n",
    "    columns=flight_outlier_cols,\n",
    "    limits=(0.01, 0.01)    # winsorize at 1% and 99%\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c1957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_outlier_cols = [\n",
    "    'Income',\n",
    "    'Customer Lifetime Value',\n",
    "    'CustomerLifetimeValue_log'\n",
    "]\n",
    "\n",
    "customer_preprocessed_wins = winsorize_dataframe(\n",
    "    customer_preprocessed,\n",
    "    columns=customer_outlier_cols,\n",
    "    limits=(0.01, 0.01)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c5f2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = 'Loyalty#'\n",
    "\n",
    "model_df = (\n",
    "    customer_preprocessed_wins\n",
    "    .merge(customer_flight_features_wins, on=id_col, how='left')\n",
    ")\n",
    "\n",
    "print(\"Final model_df shape:\", model_df.shape)\n",
    "model_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe01dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for remaining missing values\n",
    "model_df.isna().sum().sort_values(ascending=False).head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f0cd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop CancellationDate (flag already exists)\n",
    "model_df = model_df.drop(columns=['CancellationDate'], errors='ignore')\n",
    "\n",
    "# Fill average distance for zero-flight customers\n",
    "model_df['AverageFlightDistance'] = model_df['AverageFlightDistance'].fillna(0)\n",
    "\n",
    "# Fill points utilization for customers with no point activity\n",
    "model_df['MeanPointsUtilization'] = model_df['MeanPointsUtilization'].fillna(0)\n",
    "\n",
    "# Fill ALL flight-related NaNs with 0\n",
    "flight_cols = [\n",
    "    'TotalFlights', 'TotalDistanceKM', 'TotalPointsAccumulated',\n",
    "    'TotalPointsRedeemed', 'MeanPointsUtilization', 'AverageFlightDistance',\n",
    "    'TotalFlights_z', 'TotalDistanceKM_z', 'FlightActivityScore'\n",
    "]\n",
    "\n",
    "for col in flight_cols:\n",
    "    model_df[col] = model_df[col].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6927b2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features for clustering\n",
    "numeric_features = [\n",
    "    'Income',\n",
    "    'CustomerLifetimeValue_log',\n",
    "    'CustomerValueScore',\n",
    "    \n",
    "    'TotalFlights',\n",
    "    'TotalDistanceKM',\n",
    "    'AverageFlightDistance',\n",
    "    'TotalPointsAccumulated',\n",
    "    'TotalPointsRedeemed',\n",
    "    'MeanPointsUtilization',\n",
    "    'FlightActivityScore',\n",
    "\n",
    "    'CancelledFlag'\n",
    "]\n",
    "\n",
    "# Categorical features to encode\n",
    "categorical_features = [\n",
    "    'EnrollmentType',  # Bronze, Silver, Gold ...\n",
    "    'Location'         # Region/Province after mapping\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed99397",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected = model_df[numeric_features + categorical_features].copy()\n",
    "df_selected.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e15d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df_selected, columns=categorical_features, drop_first=True)\n",
    "df_encoded.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6296ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_encoded)\n",
    "\n",
    "X_scaled[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca7e97d",
   "metadata": {},
   "source": [
    "# DBSCAN \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3419c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dbscan_outliers(df: pd.DataFrame, features: list, eps=1.9, min_samples=20):\n",
    "    \"\"\"\n",
    "    Apply DBSCAN to identify outliers in the dataset.\n",
    "    Returns a DataFrame with original data and DBSCAN labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples, n_jobs=-1)\n",
    "    labels = dbscan.fit_predict(df[features])\n",
    "    df_out = df.copy()\n",
    "    df_out['DBSCAN_Label'] = labels\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2802c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outliers = get_dbscan_outliers(df_selected, numeric_features, eps=1.9, min_samples=20)\n",
    "df_outliers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ca40b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outliers['DBSCAN_Label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec503e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = n_clusters = len(set(labels)) - (1 if -1 in labels.values else 0)\n",
    "print(f\"Estimated number of clusters: {n_clusters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1ff7fe",
   "metadata": {},
   "source": [
    " Given the fact that -1 represents the outliers, than there are two clusters (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1184719",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n6. Distribution:\")\n",
    "for label in sorted(labels.unique()):\n",
    "    count = (labels == label).sum()\n",
    "    pct = count / len(labels) * 100\n",
    "    type = \"OUTLIERS\" if label == -1 else f\"Cluster {label}\"\n",
    "    print(f\"   {type:15} → {count:5} points ({pct:5.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f636fe50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataMining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
