{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "642b95d6",
   "metadata": {},
   "source": [
    "# Group 20 — Exploratory Data Analysis\n",
    "This notebook performs an initial exploratory data analysis (EDA) on the provided customer and flights databases.\n",
    "The goals are:\n",
    "- Inspect imports and data quality\n",
    "- Identify missing or strange values\n",
    "- Preprocess data for downstream modeling\n",
    "\n",
    "## Table of contents\n",
    "- [Import data](#import-data)\n",
    "- [Data Exploration](#data-exploration)\n",
    "  - [Customer DB](#customer-db)\n",
    "    - [Inspect import](#inspect-import-customer)\n",
    "    - [Check categorical values](#check-cat-values-customer)\n",
    "    - [Check Outliers](#check-outliers)\n",
    "  - [Flights DB](#flights-db)\n",
    "    - [Inspect import](#inspect-import-flights)\n",
    "    - [Check Outliers](#check-outliers-flight)\n",
    "- [Preprocessing](#preprocessing)\n",
    "  - [Missing Values](#missing-values)\n",
    "  - [Convert data types](#convert-data-types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34bb2db",
   "metadata": {},
   "source": [
    "# <a id=\"import-data\"></a> Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0215ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Load the data\n",
    "\n",
    "customer_db = pd.read_csv(\"data/DM_AIAI_CustomerDB.csv\", index_col=0 )\n",
    "flights_db = pd.read_csv(\"data/DM_AIAI_FlightsDB.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3073ffd5",
   "metadata": {},
   "source": [
    "# <a id=\"data-exploration\"></a> Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4388d9cb",
   "metadata": {},
   "source": [
    "### <a id=\"customer-db\"></a> Customer DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f289a5ee",
   "metadata": {},
   "source": [
    "#### <a id=\"inspect-import-customer\"></a> Inspect import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9216492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f61b25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_db.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82431c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_loyalty_ids = customer_db[customer_db['Loyalty#'].duplicated()]['Loyalty#'].unique()\n",
    "print(f\"Number of unique Duplicated Loyalty IDs: {len(duplicated_loyalty_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781576b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='LoyaltyStatus', y='Income', data=customer_db.dropna(subset=['Income']))\n",
    "plt.title('Income by Loyalty Tier')\n",
    "plt.xlabel('Loyalty Tier')\n",
    "plt.ylabel('Income')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f28c47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_db.groupby('LoyaltyStatus')['Income'].agg(['count', 'mean', 'median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24235a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "groups = [group[\"Income\"].dropna() for _, group in customer_db.groupby(\"Education\")]\n",
    "f_stat, p_val = stats.f_oneway(*groups)\n",
    "print(f\"ANOVA F-statistic: {f_stat:.3f}, p-value: {p_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdccee5",
   "metadata": {},
   "source": [
    "#### <a id=\"check-cat-values-customer\"></a> Check categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1054706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\n",
    "     'Province or State', 'City', 'Gender', 'Education',\n",
    "    'Location Code', 'Marital Status', 'LoyaltyStatus', 'EnrollmentType'\n",
    "]\n",
    "\n",
    "# Create the figure and axes\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=math.ceil(len(categorical_cols) / 3),\n",
    "    ncols=3,\n",
    "    figsize=(15, 15)\n",
    ")\n",
    "# TODO: remove Country subplot\n",
    "\n",
    "# Generate a plot for each categorical column\n",
    "for ax, col in zip(axes.flatten(), categorical_cols):\n",
    "    customer_db[col].value_counts().plot(\n",
    "        kind='barh',\n",
    "        ax=ax,\n",
    "        title=f'Distribution of {col}'\n",
    "    )\n",
    "    ax.set_xlabel(\"Count\")\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c693de",
   "metadata": {},
   "source": [
    "### Scatter Plot for the customer dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8fc35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['Income', 'Customer Lifetime Value']\n",
    "\n",
    "customer_db_reset = customer_db.reset_index()\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=customer_db_reset,\n",
    "    x='Income',        \n",
    "    y='Customer Lifetime Value',\n",
    "    alpha=0.6\n",
    ")\n",
    "\n",
    "plt.suptitle('Relationships between Customer Features', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a7d1fa",
   "metadata": {},
   "source": [
    "### Observations from the scatter plot\n",
    "\n",
    "- **No clear linear relationship:** Income and Customer Lifetime Value don't have a strong correlation, given the fact that the points are widely scattered across all income levels, suggesting that higher income does not necessarily imply an higher customer lifetime value.\n",
    "\n",
    "- **Cluster of low-income customers:** There is a noticeable dense cluster of data points near Income = 0, indicating that a large portion of customers have very low (or missing) income values\n",
    "\n",
    "- **High Variance in Customer Lifetime Value:** Across all income ranges, the CLV varies greatly — some customers with low income have high CLV, and vice versa. This suggests that factors other than income likely play a more important role in determining CLV.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee4a6d0",
   "metadata": {},
   "source": [
    "### <a id=\"check-outliers\"></a> Check Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57e609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_features = [\"Income\", \"Customer Lifetime Value\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db434c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the histogram of income and customer lifetime value\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "for ax, feat in zip(np.atleast_1d(axes).flatten(), numeric_features):\n",
    "    ax.hist(customer_db[feat].dropna(), bins=30)\n",
    "    ax.set_title(feat, y=-0.13)\n",
    "\n",
    "plt.suptitle(\"Customer DB — Histogram (Income)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9ae5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : label box plots correctly\n",
    "\n",
    "#checking boxplot for income and customer lifetime value\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 3))\n",
    "\n",
    "for ax, feat in zip(np.atleast_1d(axes).ravel(), numeric_features):\n",
    "    ax.boxplot(customer_db[feat].dropna().values, vert=False)\n",
    "\n",
    "plt.suptitle(\"Income and Lifetime Value Boxplots - Customer DB\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6a7812",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cust = customer_db.isna().sum()\n",
    "display(pd.DataFrame({\n",
    "    'Missing Count': missing_cust[missing_cust > 0],\n",
    "    '%': (missing_cust[missing_cust > 0] / len(customer_db) * 100).round(2)\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6516ed4d",
   "metadata": {},
   "source": [
    "### <a id=\"flights-db\"></a> Flights DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9132a5a9",
   "metadata": {},
   "source": [
    "#### <a id=\"inspect-import-flights\"></a> Inspect import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1243ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9cd868-32dd-4fb0-8860-36f8dbbd798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_db.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55333cb1",
   "metadata": {},
   "source": [
    "### <a id=\"check-outliers-flight\"></a> Check Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa21dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "    \"NumFlights\",\n",
    "    \"NumFlightsWithCompanions\",\n",
    "    \"DistanceKM\",\n",
    "    \"PointsAccumulated\",\n",
    "    \"PointsRedeemed\",\n",
    "    \"DollarCostPointsRedeemed\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea04b348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Use bar plots for discrete values\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 8), constrained_layout=True)\n",
    "\n",
    "for ax, feat in zip(axes.flatten(), numeric_features):\n",
    "    ax.hist(flights_db[feat].dropna(), bins=20)\n",
    "    ax.set_title(feat, y=-0.13)\n",
    "\n",
    "plt.suptitle(\"Flights DB — Histograms\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68be2949",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(20, 8), constrained_layout=True)\n",
    "\n",
    "for ax, feat in zip(axes.flatten(), numeric_features):\n",
    "    unique_vals = flights_db[feat].nunique()\n",
    "    \n",
    "    # Se poucos valores distintos → bar plot\n",
    "    if unique_vals < 30:\n",
    "        value_counts = flights_db[feat].value_counts().sort_index()\n",
    "        ax.bar(value_counts.index, value_counts.values)\n",
    "    else:\n",
    "        ax.hist(flights_db[feat].dropna(), bins=20)\n",
    "    \n",
    "    ax.set_title(feat, y=-0.13)\n",
    "\n",
    "plt.suptitle(\"Flights DB — Bar Plots (discrete) and Histograms (continuous)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fac10bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking to see if there are float flights or float flight companions \n",
    "invalid_fractional_flights = flights_db[\n",
    "    (flights_db['NumFlights'] % 1 != 0) |\n",
    "    (flights_db['NumFlightsWithCompanions'] % 1 != 0)\n",
    "]\n",
    "\n",
    "print(f\"Number of rows with impossible fractional flight counts: {len(invalid_fractional_flights)}\")\n",
    "if not invalid_fractional_flights.empty:\n",
    "    display(invalid_fractional_flights[[ 'Year', 'Month', 'NumFlights', 'NumFlightsWithCompanions']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d04fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking to see if there are any individuals that were not on a flight but their recorded distance was >0\n",
    "invalid_flights = flights_db[(flights_db['NumFlights'] == 0) & (flights_db['DistanceKM'] > 0)]\n",
    "\n",
    "print(f\"Number of inconsistent rows (NumFlights=0 & DistanceKM>0): {len(invalid_flights)}\")\n",
    "if not invalid_flights.empty:\n",
    "    display(invalid_flights.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a930c6",
   "metadata": {},
   "source": [
    "### Scatter Plots for the flights dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5304f0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : check this pairplot\n",
    "g = sns.pairplot(\n",
    "    data=flights_db[numeric_features],\n",
    "    diag_kind='scatter',      \n",
    "    plot_kws={'alpha': 0.5},\n",
    "    height=2\n",
    ")\n",
    "\n",
    "plt.suptitle('Relationships between Flight Features', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d4e083",
   "metadata": {},
   "source": [
    "### Observations from the Scatter Plot\n",
    "\n",
    "#### **Strong Linear Correlations**\n",
    "- **DistanceKM and PointsAccumulated:**  \n",
    "  There is a *nearly perfect linear correlation* between these two variables. This makes sense since loyalty programs typically award points proportional to the distance flown. The diagonal line pattern confirms this rule-based relationship.  \n",
    "  → **Interpretation:** The more kilometers a customer flies, the more points they accumulate — a direct, systematic link rather than behavioral variation.\n",
    "\n",
    "- **PointsRedeemed and DollarCostPointsRedeemed:**  \n",
    "  This pair also shows a *perfect positive linear relationship*. The cost in dollars grows in direct proportion to the points redeemed.  \n",
    "  → **Interpretation:** The airline’s redemption system consistently converts points to monetary value at a fixed rate, suggesting a stable and predictable reward conversion mechanism.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Moderate Positive Trends**\n",
    "- **NumFlights and DistanceKM / PointsAccumulated:**  \n",
    "  Customers who take more flights generally cover more distance and accumulate more points, although with more variation than the linear cases above.  \n",
    "  → **Interpretation:** Some customers may take many short flights, while others take fewer long ones — explaining the moderate rather than perfect correlation.\n",
    "\n",
    "- **NumFlights and NumFlightsWithCompanions:**  \n",
    "  There’s a clear positive association — passengers who fly more frequently also tend to fly more often with companions.  \n",
    "  → **Interpretation:** This could indicate a segment of loyal customers who consistently travel with family, friends, or colleagues, possibly representing a valuable demographic for group travel promotions.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Clustered Data Patterns**\n",
    "\n",
    "- **Clustered distributions:**  \n",
    "  For many features, data points appear concentrated in specific ranges (e.g., low flight counts, moderate distances).  \n",
    "  → **Interpretation:** Most customers likely fly infrequently, while a smaller subset are heavy travelers. This skew could affect model training if not accounted for.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Weak or Nonlinear Relationships**\n",
    "- **PointsRedeemed and NumFlightsWithCompanions:**  \n",
    "  No clear pattern is visible here, suggesting that redeeming points does not depend on whether the customer tends to fly alone or with companions.  \n",
    "  → **Interpretation:** Redemption behavior might be more influenced by individual loyalty strategies, travel frequency, or availability of redemption opportunities.\n",
    "\n",
    "- **DistanceKM and PointsRedeemed:**  \n",
    "  The relationship seems weakly positive but scattered, implying that not all high-distance travelers redeem their points frequently.  \n",
    "  → **Interpretation:** Some high-value customers may be accumulating points for larger future redemptions or are less engaged in reward usage.\n",
    "\n",
    "---\n",
    "\n",
    "#### **General Insights**\n",
    "- The pair plot confirms logical relationships within the airline loyalty data — distance, flights, and accumulated points are strongly linked, while redemption behavior is more customer-specific.  \n",
    "- The lack of strong cross-feature noise suggests data integrity is good. However, some discretization and clustering may require normalization for modeling or visualization purposes.  \n",
    "- From a business perspective, segmenting customers based on flight frequency, distance traveled, and redemption patterns could yield meaningful insights for targeted marketing or retention strategies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e115f665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking boxplot \n",
    "fig, axes = plt.subplots(2, 3,figsize=(20, 8), constrained_layout=True)\n",
    "\n",
    "for ax, feat in zip(axes.flatten(), numeric_features):\n",
    "    sns.boxplot(data=flights_db, x=feat, ax=ax)\n",
    "    ax.set_xlabel(feat)                           \n",
    "    ax.set_ylabel('')        \n",
    "\n",
    "fig.suptitle(\"Flights DB — Box Plots\", y=1.02)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc68cd13",
   "metadata": {},
   "source": [
    "## Correlation Matrix for the flights dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f55873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "corr = flights_db[numeric_features].corr(method=\"pearson\")\n",
    "\n",
    "sns.heatmap(data=corr, annot=True, )\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015eefae",
   "metadata": {},
   "source": [
    "# Observations of the Correlation Matrix\n",
    "\n",
    "| Pair | Correlation | Interpretation |\n",
    "|------|--------------|----------------|\n",
    "| NumFlights and DistanceKM | 0.62 | Strong positive — more flights generally means more total distance flown. |\n",
    "| NumFlights and PointsAccumulated | 0.62 | Strong positive — more flights results in more points earned. |\n",
    "| NumFlights and NumFlightsWithCompanions | 0.51 | Moderate positive — people who fly often also tend to fly with companions more. |\n",
    "| NumFlightsWithCompanions and DistanceKM | 0.39 | Moderate — more companion flights slightly increase total distance. |\n",
    "| PointsRedeemed and DollarCostPointsRedeemed | 1.00 | Perfect correlation — these two represent the same underlying concept (points redeemed vs. their dollar cost).\n",
    "| PointsRedeemed and NumFlights / DistanceKM / PointsAccumulated | 0.19–0.34 | Weak relationships — redeeming points doesn’t strongly depend on flying behavior in this dataset. |\n",
    "\n",
    "\n",
    "### Insights\n",
    "\n",
    "The dataset splits into two main groups:\n",
    "\n",
    "- **Flight activity metrics:**  \n",
    "  `NumFlights`, `NumFlightsWithCompanions`, `DistanceKM`, `PointsAccumulated`\n",
    "\n",
    "- **Redemption metrics:**  \n",
    "  `PointsRedeemed`, `DollarCostPointsRedeemed`\n",
    "\n",
    "---\n",
    "\n",
    "- These two groups are weakly correlated with each other, suggesting that accumulating points and redeeming them behave independently.  \n",
    "\n",
    "- The perfect correlation between `PointsRedeemed` and `DollarCostPointsRedeemed` indicates redundancy — there is only need to keep one of them (`PointsRedeemed`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216fa7a8",
   "metadata": {},
   "source": [
    "# <a id=\"preprocessing\"></a> Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601902ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates in customer_db based on 'Loyalty#'\n",
    "customer_db_cleaned = customer_db[~customer_db['Loyalty#'].isin(duplicated_loyalty_ids)]\n",
    "\n",
    "# Remove duplicates in flights_db based on 'Loyalty#'\n",
    "flights_db_cleaned = flights_db[~flights_db['Loyalty#'].isin(duplicated_loyalty_ids)]\n",
    "\n",
    "# Number of records after removing duplicates\n",
    "print(f'% of Customer DB records remaining: {round(customer_db_cleaned.shape[0] / customer_db.shape[0], 2)}')\n",
    "print(f'% of Flights DB records remaining: {round(flights_db_cleaned.shape[0] / flights_db.shape[0], 2)}')\n",
    "\n",
    "# Merge the cleaned dataframes\n",
    "merged_db = customer_db_cleaned.merge(flights_db_cleaned, on='Loyalty#', how='inner')\n",
    "\n",
    "# Check if the merge has the same number of rows as flights_db_cleaned\n",
    "print(f'Number of records in merged DB: {merged_db.shape[0] == flights_db_cleaned.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d4fe57",
   "metadata": {},
   "source": [
    "## <a id=\"missing-values\"></a> Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd98040",
   "metadata": {},
   "source": [
    "In this step, we will create a simple helper function called missing_report() to check how many missing values exist in each column of both datasets: CustomerDB and FlightsDB. This will help us identify which features might need cleaning or imputation later. The function will return the total number of missing entries and their corresponding percentage, sorted from the highest to the lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab33c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_report(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.isna().agg(['sum', 'mean']).T\n",
    "    out.columns = ['Total', 'Percentage']\n",
    "    out['Percentage'] = (out['Percentage'] * 100).round(2)\n",
    "    return out.sort_values(['Total', 'Percentage'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509e1f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_missing = missing_report(customer_db)\n",
    "flights_missing  = missing_report(flights_db)\n",
    "\n",
    "customer_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bfa04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff4a99f",
   "metadata": {},
   "source": [
    "After running the missing values report, we can see that the CancellationID column in the CustomerDB dataset has a very high proportion of missing values (around 86%). This actually makes sense: most customers likely never cancelled their membership or subscription, so this field would naturally remain empty for them.\n",
    "\n",
    "Apart from that, only two other columns: Income and Customer Life have a very small number of missing records (around 0.12%), which is negligible. All other fields in CustomerDB, as well as every column in the FlightsDB dataset, are completely filled, showing that both datasets have excellent data quality overall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18077a44",
   "metadata": {},
   "source": [
    "## <a id=\"convert-data-types\"></a> Convert data types"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fall2526",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
